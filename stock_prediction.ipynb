{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 50\n",
    "LOOKUP_STEP = 15\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "TEST_SIZE = 0.2\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "N_LAYERS = 2\n",
    "CELL = LSTM\n",
    "UNITS = 256\n",
    "DROPOUT = 0.4\n",
    "BIDIRECTIONAL = False\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "ticker = \"ADANIENT.NS\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True, test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    if isinstance(ticker, str):\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    result = {}\n",
    "    result['df'] = df.copy()\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    result['last_sequence'] = last_sequence\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3, loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS, dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0224\n",
      "Epoch 1: val_loss improved from inf to 0.00027, saving model to results\\2022-07-16_ADANIENT.NS-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "62/62 [==============================] - 32s 429ms/step - loss: 0.0013 - mean_absolute_error: 0.0224 - val_loss: 2.7359e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.4991e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 2: val_loss improved from 0.00027 to 0.00013, saving model to results\\2022-07-16_ADANIENT.NS-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "62/62 [==============================] - 25s 409ms/step - loss: 3.4991e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2789e-04 - val_mean_absolute_error: 0.0080\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 4.1830e-04 - mean_absolute_error: 0.0135\n",
      "Epoch 3: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 26s 418ms/step - loss: 4.1830e-04 - mean_absolute_error: 0.0135 - val_loss: 1.9483e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 4.0809e-04 - mean_absolute_error: 0.0124\n",
      "Epoch 4: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 27s 439ms/step - loss: 4.0809e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3516e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.9105e-04 - mean_absolute_error: 0.0129\n",
      "Epoch 5: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 29s 461ms/step - loss: 3.9105e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3544e-04 - val_mean_absolute_error: 0.0074\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.0916e-04 - mean_absolute_error: 0.0113\n",
      "Epoch 6: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 32s 518ms/step - loss: 3.0916e-04 - mean_absolute_error: 0.0113 - val_loss: 5.1823e-04 - val_mean_absolute_error: 0.0164\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 6.0531e-04 - mean_absolute_error: 0.0177\n",
      "Epoch 7: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 26s 422ms/step - loss: 6.0531e-04 - mean_absolute_error: 0.0177 - val_loss: 2.2052e-04 - val_mean_absolute_error: 0.0085\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 4.2723e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 8: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 26s 424ms/step - loss: 4.2723e-04 - mean_absolute_error: 0.0137 - val_loss: 1.3066e-04 - val_mean_absolute_error: 0.0081\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.4392e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 9: val_loss did not improve from 0.00013\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 3.4392e-04 - mean_absolute_error: 0.0119 - val_loss: 1.5135e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.6895e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 10: val_loss improved from 0.00013 to 0.00012, saving model to results\\2022-07-16_ADANIENT.NS-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "62/62 [==============================] - 27s 428ms/step - loss: 3.6895e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2424e-04 - val_mean_absolute_error: 0.0079\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(data[\"X_test\"], data[\"y_test\"]), callbacks=[checkpointer, tensorboard], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graph(test_df):\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, final_df[\"adjclose\"], final_df[f\"adjclose_{LOOKUP_STEP}\"], final_df[f\"true_adjclose_{LOOKUP_STEP}\"]))\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, final_df[\"adjclose\"], final_df[f\"adjclose_{LOOKUP_STEP}\"], final_df[f\"true_adjclose_{LOOKUP_STEP}\"]))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 2296.53\n",
      "huber_loss loss: 0.00012424371379893273\n",
      "Mean Absolute Error: 18.90207660809535\n",
      "Accuracy score: 0.4862665310274669\n",
      "Total buy profit: 5452.955101013184\n",
      "Total sell profit: -1491.4278523977846\n",
      "Total profit: 3961.527248615399\n",
      "Profit per trade: 4.030037892792878\n"
     ]
    }
   ],
   "source": [
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-09-10</th>\n",
       "      <td>1.177152</td>\n",
       "      <td>1.177152</td>\n",
       "      <td>1.177152</td>\n",
       "      <td>1.177152</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.325665</td>\n",
       "      <td>0.031913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-12</th>\n",
       "      <td>1.153394</td>\n",
       "      <td>1.176386</td>\n",
       "      <td>1.153394</td>\n",
       "      <td>1.168722</td>\n",
       "      <td>0.035785</td>\n",
       "      <td>504609.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.327724</td>\n",
       "      <td>0.031538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-16</th>\n",
       "      <td>1.172554</td>\n",
       "      <td>1.180217</td>\n",
       "      <td>1.157226</td>\n",
       "      <td>1.166423</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>511485.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.323622</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-18</th>\n",
       "      <td>1.153394</td>\n",
       "      <td>1.171787</td>\n",
       "      <td>1.153394</td>\n",
       "      <td>1.161058</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>506044.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.324625</td>\n",
       "      <td>0.034917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-19</th>\n",
       "      <td>1.157226</td>\n",
       "      <td>1.164890</td>\n",
       "      <td>1.153394</td>\n",
       "      <td>1.157226</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>485989.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.327187</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-30</th>\n",
       "      <td>1.015447</td>\n",
       "      <td>1.110477</td>\n",
       "      <td>1.015447</td>\n",
       "      <td>1.081355</td>\n",
       "      <td>0.033110</td>\n",
       "      <td>506827.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.405178</td>\n",
       "      <td>0.034002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-01</th>\n",
       "      <td>0.984025</td>\n",
       "      <td>1.072925</td>\n",
       "      <td>0.984025</td>\n",
       "      <td>1.042270</td>\n",
       "      <td>0.031913</td>\n",
       "      <td>517996.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.427740</td>\n",
       "      <td>0.033955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-17</th>\n",
       "      <td>1.121207</td>\n",
       "      <td>1.122739</td>\n",
       "      <td>1.112010</td>\n",
       "      <td>1.115842</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>505365.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.365538</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-24</th>\n",
       "      <td>1.080589</td>\n",
       "      <td>1.088252</td>\n",
       "      <td>1.010849</td>\n",
       "      <td>1.062962</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>623754.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.372437</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-25</th>\n",
       "      <td>1.049934</td>\n",
       "      <td>1.056831</td>\n",
       "      <td>1.013914</td>\n",
       "      <td>1.033073</td>\n",
       "      <td>0.031632</td>\n",
       "      <td>565910.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.387758</td>\n",
       "      <td>0.036911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-10-29</th>\n",
       "      <td>1.019279</td>\n",
       "      <td>1.042270</td>\n",
       "      <td>1.019279</td>\n",
       "      <td>1.035373</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>493687.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.428278</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-01</th>\n",
       "      <td>1.050700</td>\n",
       "      <td>1.062962</td>\n",
       "      <td>1.030774</td>\n",
       "      <td>1.046102</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>489668.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.452953</td>\n",
       "      <td>0.036254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-12</th>\n",
       "      <td>1.140366</td>\n",
       "      <td>1.141899</td>\n",
       "      <td>1.104346</td>\n",
       "      <td>1.130403</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>513730.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.402372</td>\n",
       "      <td>0.035949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-11-28</th>\n",
       "      <td>1.195545</td>\n",
       "      <td>1.196311</td>\n",
       "      <td>1.184049</td>\n",
       "      <td>1.187115</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>453641.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.292913</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-12</th>\n",
       "      <td>1.019279</td>\n",
       "      <td>1.149562</td>\n",
       "      <td>1.011615</td>\n",
       "      <td>1.131936</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>714140.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.320772</td>\n",
       "      <td>0.033978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-30</th>\n",
       "      <td>1.115842</td>\n",
       "      <td>1.122739</td>\n",
       "      <td>1.105113</td>\n",
       "      <td>1.111244</td>\n",
       "      <td>0.034025</td>\n",
       "      <td>137334.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.330664</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>1.096683</td>\n",
       "      <td>1.115076</td>\n",
       "      <td>1.096683</td>\n",
       "      <td>1.106645</td>\n",
       "      <td>0.033884</td>\n",
       "      <td>404318.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.325109</td>\n",
       "      <td>0.033321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>1.096683</td>\n",
       "      <td>1.103580</td>\n",
       "      <td>1.092084</td>\n",
       "      <td>1.097449</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>405962.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.365484</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-17</th>\n",
       "      <td>1.092851</td>\n",
       "      <td>1.102814</td>\n",
       "      <td>1.089019</td>\n",
       "      <td>1.093617</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>404318.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.373619</td>\n",
       "      <td>0.030576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-20</th>\n",
       "      <td>1.066794</td>\n",
       "      <td>1.098982</td>\n",
       "      <td>1.066794</td>\n",
       "      <td>1.087486</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>430063.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>-16.377956</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close  adjclose    volume  \\\n",
       "2002-09-10  1.177152  1.177152  1.177152  1.177152  0.036043       0.0   \n",
       "2002-09-12  1.153394  1.176386  1.153394  1.168722  0.035785  504609.0   \n",
       "2002-09-16  1.172554  1.180217  1.157226  1.166423  0.035715  511485.0   \n",
       "2002-09-18  1.153394  1.171787  1.153394  1.161058  0.035550  506044.0   \n",
       "2002-09-19  1.157226  1.164890  1.153394  1.157226  0.035433  485989.0   \n",
       "2002-09-30  1.015447  1.110477  1.015447  1.081355  0.033110  506827.0   \n",
       "2002-10-01  0.984025  1.072925  0.984025  1.042270  0.031913  517996.0   \n",
       "2002-10-17  1.121207  1.122739  1.112010  1.115842  0.034166  505365.0   \n",
       "2002-10-24  1.080589  1.088252  1.010849  1.062962  0.032547  623754.0   \n",
       "2002-10-25  1.049934  1.056831  1.013914  1.033073  0.031632  565910.0   \n",
       "2002-10-29  1.019279  1.042270  1.019279  1.035373  0.031702  493687.0   \n",
       "2002-11-01  1.050700  1.062962  1.030774  1.046102  0.032031  489668.0   \n",
       "2002-11-12  1.140366  1.141899  1.104346  1.130403  0.034612  513730.0   \n",
       "2002-11-28  1.195545  1.196311  1.184049  1.187115  0.036348  453641.0   \n",
       "2002-12-12  1.019279  1.149562  1.011615  1.131936  0.034659  714140.0   \n",
       "2002-12-30  1.115842  1.122739  1.105113  1.111244  0.034025  137334.0   \n",
       "2003-01-01  1.096683  1.115076  1.096683  1.106645  0.033884  404318.0   \n",
       "2003-01-15  1.096683  1.103580  1.092084  1.097449  0.033603  405962.0   \n",
       "2003-01-17  1.092851  1.102814  1.089019  1.093617  0.033485  404318.0   \n",
       "2003-01-20  1.066794  1.098982  1.066794  1.087486  0.033298  430063.0   \n",
       "\n",
       "                 ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
       "2002-09-10  ADANIENT.NS   -16.325665          0.031913         0.0   \n",
       "2002-09-12  ADANIENT.NS   -16.327724          0.031538         0.0   \n",
       "2002-09-16  ADANIENT.NS   -16.323622          0.032124         0.0   \n",
       "2002-09-18  ADANIENT.NS   -16.324625          0.034917         0.0   \n",
       "2002-09-19  ADANIENT.NS   -16.327187          0.033908         0.0   \n",
       "2002-09-30  ADANIENT.NS   -16.405178          0.034002         0.0   \n",
       "2002-10-01  ADANIENT.NS   -16.427740          0.033955         0.0   \n",
       "2002-10-17  ADANIENT.NS   -16.365538          0.032735         0.0   \n",
       "2002-10-24  ADANIENT.NS   -16.372437          0.035996         0.0   \n",
       "2002-10-25  ADANIENT.NS   -16.387758          0.036911         0.0   \n",
       "2002-10-29  ADANIENT.NS   -16.428278          0.036724         0.0   \n",
       "2002-11-01  ADANIENT.NS   -16.452953          0.036254         0.0   \n",
       "2002-11-12  ADANIENT.NS   -16.402372          0.035949         0.0   \n",
       "2002-11-28  ADANIENT.NS   -16.292913          0.034612         0.0   \n",
       "2002-12-12  ADANIENT.NS   -16.320772          0.033978         0.0   \n",
       "2002-12-30  ADANIENT.NS   -16.330664          0.033298         0.0   \n",
       "2003-01-01  ADANIENT.NS   -16.325109          0.033321         0.0   \n",
       "2003-01-15  ADANIENT.NS   -16.365484          0.030763         0.0   \n",
       "2003-01-17  ADANIENT.NS   -16.373619          0.030576         0.0   \n",
       "2003-01-20  ADANIENT.NS   -16.377956          0.030552         0.0   \n",
       "\n",
       "            sell_profit  \n",
       "2002-09-10     0.004130  \n",
       "2002-09-12     0.004247  \n",
       "2002-09-16     0.003590  \n",
       "2002-09-18     0.000634  \n",
       "2002-09-19     0.001525  \n",
       "2002-09-30    -0.000892  \n",
       "2002-10-01    -0.002042  \n",
       "2002-10-17     0.001431  \n",
       "2002-10-24    -0.003449  \n",
       "2002-10-25    -0.005280  \n",
       "2002-10-29    -0.005022  \n",
       "2002-11-01    -0.004224  \n",
       "2002-11-12    -0.001338  \n",
       "2002-11-28     0.001736  \n",
       "2002-12-12     0.000681  \n",
       "2002-12-30     0.000727  \n",
       "2003-01-01     0.000563  \n",
       "2003-01-15     0.002839  \n",
       "2003-01-17     0.002910  \n",
       "2003-01-20     0.002745  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>1692.500000</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1687.650024</td>\n",
       "      <td>1732.250000</td>\n",
       "      <td>1731.513916</td>\n",
       "      <td>2159661.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1767.939819</td>\n",
       "      <td>1675.487671</td>\n",
       "      <td>-56.026245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>1734.000000</td>\n",
       "      <td>1745.000000</td>\n",
       "      <td>1701.099976</td>\n",
       "      <td>1708.099976</td>\n",
       "      <td>1707.374146</td>\n",
       "      <td>1544077.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1771.373779</td>\n",
       "      <td>1697.478394</td>\n",
       "      <td>-9.895752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>1719.900024</td>\n",
       "      <td>1730.800049</td>\n",
       "      <td>1689.500000</td>\n",
       "      <td>1699.099976</td>\n",
       "      <td>1698.378052</td>\n",
       "      <td>1295933.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1784.392212</td>\n",
       "      <td>1714.221191</td>\n",
       "      <td>15.843140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>1885.000000</td>\n",
       "      <td>1908.500000</td>\n",
       "      <td>1830.050049</td>\n",
       "      <td>1840.949951</td>\n",
       "      <td>1840.167725</td>\n",
       "      <td>2294146.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1890.247192</td>\n",
       "      <td>1782.392334</td>\n",
       "      <td>-57.775391</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>1724.599976</td>\n",
       "      <td>1791.900024</td>\n",
       "      <td>1718.099976</td>\n",
       "      <td>1783.150024</td>\n",
       "      <td>1782.392334</td>\n",
       "      <td>1674022.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1809.836670</td>\n",
       "      <td>1643.101562</td>\n",
       "      <td>-139.290771</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-23</th>\n",
       "      <td>1682.000000</td>\n",
       "      <td>1717.500000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>1688.699951</td>\n",
       "      <td>1687.982422</td>\n",
       "      <td>1285012.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1777.829468</td>\n",
       "      <td>1818.876831</td>\n",
       "      <td>130.894409</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28</th>\n",
       "      <td>1603.750000</td>\n",
       "      <td>1651.099976</td>\n",
       "      <td>1592.250000</td>\n",
       "      <td>1644.449951</td>\n",
       "      <td>1643.751221</td>\n",
       "      <td>1869037.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1725.007324</td>\n",
       "      <td>1810.230469</td>\n",
       "      <td>166.479248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>1609.599976</td>\n",
       "      <td>1669.949951</td>\n",
       "      <td>1608.000000</td>\n",
       "      <td>1656.550049</td>\n",
       "      <td>1655.846191</td>\n",
       "      <td>1498176.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1693.863770</td>\n",
       "      <td>2013.893921</td>\n",
       "      <td>358.047729</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1757.000000</td>\n",
       "      <td>1721.199951</td>\n",
       "      <td>1734.099976</td>\n",
       "      <td>1733.363159</td>\n",
       "      <td>1354129.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1728.344360</td>\n",
       "      <td>2064.972168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-331.609009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>1732.000000</td>\n",
       "      <td>1752.449951</td>\n",
       "      <td>1722.449951</td>\n",
       "      <td>1736.099976</td>\n",
       "      <td>1735.362305</td>\n",
       "      <td>659190.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1748.897339</td>\n",
       "      <td>2138.940918</td>\n",
       "      <td>403.578613</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>1775.599976</td>\n",
       "      <td>1823.599976</td>\n",
       "      <td>1760.000000</td>\n",
       "      <td>1819.650024</td>\n",
       "      <td>1818.876831</td>\n",
       "      <td>2392329.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>1795.067749</td>\n",
       "      <td>2170.027588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-351.150757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>2153.750000</td>\n",
       "      <td>2182.850098</td>\n",
       "      <td>2124.199951</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2159.082275</td>\n",
       "      <td>2259018.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2062.277588</td>\n",
       "      <td>2331.009033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-171.926758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-21</th>\n",
       "      <td>2216.000000</td>\n",
       "      <td>2293.550049</td>\n",
       "      <td>2203.899902</td>\n",
       "      <td>2286.350098</td>\n",
       "      <td>2285.378662</td>\n",
       "      <td>2243636.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2183.317383</td>\n",
       "      <td>2053.277100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-12</th>\n",
       "      <td>2103.000000</td>\n",
       "      <td>2113.600098</td>\n",
       "      <td>2011.050049</td>\n",
       "      <td>2045.199951</td>\n",
       "      <td>2044.330933</td>\n",
       "      <td>1553685.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2171.375488</td>\n",
       "      <td>2208.461182</td>\n",
       "      <td>164.130249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18</th>\n",
       "      <td>2199.699951</td>\n",
       "      <td>2216.899902</td>\n",
       "      <td>2172.000000</td>\n",
       "      <td>2181.100098</td>\n",
       "      <td>2180.173340</td>\n",
       "      <td>1296983.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2131.918701</td>\n",
       "      <td>2176.274902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-23</th>\n",
       "      <td>2231.750000</td>\n",
       "      <td>2245.000000</td>\n",
       "      <td>2155.649902</td>\n",
       "      <td>2170.649902</td>\n",
       "      <td>2169.727539</td>\n",
       "      <td>1455450.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2150.754883</td>\n",
       "      <td>2078.866211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.861328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>2168.000000</td>\n",
       "      <td>2181.449951</td>\n",
       "      <td>2066.199951</td>\n",
       "      <td>2074.149902</td>\n",
       "      <td>2073.268555</td>\n",
       "      <td>1382448.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2152.048340</td>\n",
       "      <td>2183.671875</td>\n",
       "      <td>110.403320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-30</th>\n",
       "      <td>2120.000000</td>\n",
       "      <td>2175.000000</td>\n",
       "      <td>2102.000000</td>\n",
       "      <td>2165.649902</td>\n",
       "      <td>2164.729736</td>\n",
       "      <td>1384584.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2117.496094</td>\n",
       "      <td>2078.966309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.763428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>2155.000000</td>\n",
       "      <td>2218.000000</td>\n",
       "      <td>2142.300049</td>\n",
       "      <td>2209.399902</td>\n",
       "      <td>2208.461182</td>\n",
       "      <td>1855167.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2138.789551</td>\n",
       "      <td>2109.453369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>2244.949951</td>\n",
       "      <td>2244.949951</td>\n",
       "      <td>2158.550049</td>\n",
       "      <td>2177.199951</td>\n",
       "      <td>2176.274902</td>\n",
       "      <td>1530739.0</td>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2178.703125</td>\n",
       "      <td>2219.156738</td>\n",
       "      <td>42.881836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open         high          low        close     adjclose  \\\n",
       "2021-12-02  1692.500000  1735.000000  1687.650024  1732.250000  1731.513916   \n",
       "2021-12-03  1734.000000  1745.000000  1701.099976  1708.099976  1707.374146   \n",
       "2022-01-07  1719.900024  1730.800049  1689.500000  1699.099976  1698.378052   \n",
       "2022-01-18  1885.000000  1908.500000  1830.050049  1840.949951  1840.167725   \n",
       "2022-02-09  1724.599976  1791.900024  1718.099976  1783.150024  1782.392334   \n",
       "2022-02-23  1682.000000  1717.500000  1670.000000  1688.699951  1687.982422   \n",
       "2022-02-28  1603.750000  1651.099976  1592.250000  1644.449951  1643.751221   \n",
       "2022-03-09  1609.599976  1669.949951  1608.000000  1656.550049  1655.846191   \n",
       "2022-03-11  1750.000000  1757.000000  1721.199951  1734.099976  1733.363159   \n",
       "2022-03-14  1732.000000  1752.449951  1722.449951  1736.099976  1735.362305   \n",
       "2022-03-17  1775.599976  1823.599976  1760.000000  1819.650024  1818.876831   \n",
       "2022-04-06  2153.750000  2182.850098  2124.199951  2160.000000  2159.082275   \n",
       "2022-04-21  2216.000000  2293.550049  2203.899902  2286.350098  2285.378662   \n",
       "2022-05-12  2103.000000  2113.600098  2011.050049  2045.199951  2044.330933   \n",
       "2022-05-18  2199.699951  2216.899902  2172.000000  2181.100098  2180.173340   \n",
       "2022-05-23  2231.750000  2245.000000  2155.649902  2170.649902  2169.727539   \n",
       "2022-05-25  2168.000000  2181.449951  2066.199951  2074.149902  2073.268555   \n",
       "2022-05-30  2120.000000  2175.000000  2102.000000  2165.649902  2164.729736   \n",
       "2022-06-02  2155.000000  2218.000000  2142.300049  2209.399902  2208.461182   \n",
       "2022-06-08  2244.949951  2244.949951  2158.550049  2177.199951  2176.274902   \n",
       "\n",
       "               volume       ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
       "2021-12-02  2159661.0  ADANIENT.NS  1767.939819       1675.487671  -56.026245   \n",
       "2021-12-03  1544077.0  ADANIENT.NS  1771.373779       1697.478394   -9.895752   \n",
       "2022-01-07  1295933.0  ADANIENT.NS  1784.392212       1714.221191   15.843140   \n",
       "2022-01-18  2294146.0  ADANIENT.NS  1890.247192       1782.392334  -57.775391   \n",
       "2022-02-09  1674022.0  ADANIENT.NS  1809.836670       1643.101562 -139.290771   \n",
       "2022-02-23  1285012.0  ADANIENT.NS  1777.829468       1818.876831  130.894409   \n",
       "2022-02-28  1869037.0  ADANIENT.NS  1725.007324       1810.230469  166.479248   \n",
       "2022-03-09  1498176.0  ADANIENT.NS  1693.863770       2013.893921  358.047729   \n",
       "2022-03-11  1354129.0  ADANIENT.NS  1728.344360       2064.972168    0.000000   \n",
       "2022-03-14   659190.0  ADANIENT.NS  1748.897339       2138.940918  403.578613   \n",
       "2022-03-17  2392329.0  ADANIENT.NS  1795.067749       2170.027588    0.000000   \n",
       "2022-04-06  2259018.0  ADANIENT.NS  2062.277588       2331.009033    0.000000   \n",
       "2022-04-21  2243636.0  ADANIENT.NS  2183.317383       2053.277100    0.000000   \n",
       "2022-05-12  1553685.0  ADANIENT.NS  2171.375488       2208.461182  164.130249   \n",
       "2022-05-18  1296983.0  ADANIENT.NS  2131.918701       2176.274902    0.000000   \n",
       "2022-05-23  1455450.0  ADANIENT.NS  2150.754883       2078.866211    0.000000   \n",
       "2022-05-25  1382448.0  ADANIENT.NS  2152.048340       2183.671875  110.403320   \n",
       "2022-05-30  1384584.0  ADANIENT.NS  2117.496094       2078.966309    0.000000   \n",
       "2022-06-02  1855167.0  ADANIENT.NS  2138.789551       2109.453369    0.000000   \n",
       "2022-06-08  1530739.0  ADANIENT.NS  2178.703125       2219.156738   42.881836   \n",
       "\n",
       "            sell_profit  \n",
       "2021-12-02     0.000000  \n",
       "2021-12-03     0.000000  \n",
       "2022-01-07     0.000000  \n",
       "2022-01-18     0.000000  \n",
       "2022-02-09     0.000000  \n",
       "2022-02-23     0.000000  \n",
       "2022-02-28     0.000000  \n",
       "2022-03-09     0.000000  \n",
       "2022-03-11  -331.609009  \n",
       "2022-03-14     0.000000  \n",
       "2022-03-17  -351.150757  \n",
       "2022-04-06  -171.926758  \n",
       "2022-04-21   232.101562  \n",
       "2022-05-12     0.000000  \n",
       "2022-05-18     3.898438  \n",
       "2022-05-23    90.861328  \n",
       "2022-05-25     0.000000  \n",
       "2022-05-30    85.763428  \n",
       "2022-06-02    99.007812  \n",
       "2022-06-08     0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
